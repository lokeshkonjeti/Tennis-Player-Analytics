{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/cvip')"
      ],
      "metadata": {
        "id": "8rhiwjQUnwwn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision pycocotools\n",
        "!git clone https://github.com/facebookresearch/detr.git\n",
        "%cd detr\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FihqUiBGnwuR",
        "outputId": "79554f70-c21e-4b61-af6d-74b0b53561c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'detr'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Total 265 (delta 0), reused 0 (delta 0), pack-reused 265 (from 1)\u001b[K\n",
            "Receiving objects: 100% (265/265), 21.19 MiB | 15.83 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "/content/cvip/detr\n",
            "Collecting pycocotools (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-install-bmk4nw8u/pycocotools_25c82423b0a44c3b93e62d0421fb6a95\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-install-bmk4nw8u/pycocotools_25c82423b0a44c3b93e62d0421fb6a95\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting panopticapi (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-install-bmk4nw8u/panopticapi_a71edec9d9914b1a835537921d7ddd70\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git /tmp/pip-install-bmk4nw8u/panopticapi_a71edec9d9914b1a835537921d7ddd70\n",
            "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.0.12)\n",
            "Collecting submitit (from -r requirements.txt (line 3))\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.15.2)\n",
            "Collecting onnx (from -r requirements.txt (line 8))\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime (from -r requirements.txt (line 9))\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 3)) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.6.0->-r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.6.0->-r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->-r requirements.txt (line 8)) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime->-r requirements.txt (line 9))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->-r requirements.txt (line 9)) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime->-r requirements.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r requirements.txt (line 9))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.17.0)\n",
            "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycocotools, panopticapi\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp311-cp311-linux_x86_64.whl size=396013 sha256=25a2565dfb898ebbb71b7a3c9b84d44a5ba9237859561b43601f9e510d3dad7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rbeh3y2v/wheels/6d/69/75/358c50a37672dfda8d74ba3b30ec49fb75d52f7c081886d503\n",
            "  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8259 sha256=dbe7ed466b4fbc3545dc64501ebdc6a3217d11ad0738abc6c20fd43c80148ebb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rbeh3y2v/wheels/1e/dc/23/d70628297e507c01e9be79a815856549c351a79f86a1af064d\n",
            "Successfully built pycocotools panopticapi\n",
            "Installing collected packages: submitit, panopticapi, onnx, humanfriendly, coloredlogs, pycocotools, onnxruntime\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.8\n",
            "    Uninstalling pycocotools-2.0.8:\n",
            "      Successfully uninstalled pycocotools-2.0.8\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.21.1 panopticapi-0.1 pycocotools-2.0 submitit-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile datasets/coco.py\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CocoDetection as TVCocoDetection\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "def make_coco_transforms(image_set):\n",
        "    normalize = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406],\n",
        "                    [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    if image_set == 'train':\n",
        "        return T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            normalize,\n",
        "        ])\n",
        "    return T.Compose([normalize])\n",
        "\n",
        "class CocoDetection(TVCocoDetection):\n",
        "    def __init__(self, img_folder, ann_file, transforms=None):\n",
        "        super().__init__(img_folder, ann_file)\n",
        "        self._transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "\n",
        "        w, h = img.size\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        image_id = self.ids[idx]\n",
        "        for obj in target:\n",
        "            bbox = obj[\"bbox\"]\n",
        "            x, y, bw, bh = bbox\n",
        "            boxes.append([x, y, x + bw, y + bh])\n",
        "            labels.append(obj[\"category_id\"])\n",
        "        target = {\n",
        "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
        "            \"image_id\": torch.tensor(image_id),\n",
        "            \"orig_size\": torch.tensor([h, w]),\n",
        "            \"size\": torch.tensor([h, w])\n",
        "        }\n",
        "\n",
        "        img = ToTensor()(img)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def build(image_set, args):\n",
        "    assert image_set in ['train', 'val', 'test']\n",
        "    root = Path(args.dataset_path)\n",
        "    PATHS = {\n",
        "        \"train\": (root / \"train\", root / \"train\" / \"_annotations.coco.json\"),\n",
        "        \"val\": (root / \"valid\", root / \"valid\" / \"_annotations.coco.json\"),\n",
        "        \"test\": (root / \"test\", root / \"test\" / \"_annotations.coco.json\"),\n",
        "    }\n",
        "    img_folder, ann_file = PATHS[image_set]\n",
        "    dataset = CocoDetection(img_folder, ann_file, transforms=make_coco_transforms(image_set))\n",
        "    return dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKzdGPGLnwrq",
        "outputId": "a975611e-9fd2-4485-ec49-c162ef05aca6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting datasets/coco.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models/build.py\n",
        "from models import build_model\n",
        "\n",
        "def build_detr(args):\n",
        "    args.num_classes -= 1\n",
        "    model, criterion, postprocessors = build_model(args)\n",
        "    return model, criterion, postprocessors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1kUPu6znwpV",
        "outputId": "7aeeafb3-894a-4365-a845-b25150531cfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing models/build.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_detr_players.py\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/cvip/detr\")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import coco\n",
        "from models.builder_detr import build_detr\n",
        "from engine import train_one_epoch, evaluate\n",
        "import util.misc as utils\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser('Train DETR', add_help=False)\n",
        "    parser.add_argument('--dataset_path', default='/content/cvip/coco', type=str) #Give the path to the dataset folder\n",
        "    parser.add_argument('--output_dir', default='./output', type=str)\n",
        "    parser.add_argument('--num_classes', default=2, type=int)\n",
        "    parser.add_argument('--epochs', default=25, type=int)\n",
        "    parser.add_argument('--lr', default=1e-4, type=float)\n",
        "    parser.add_argument('--lr_backbone', default=1e-5, type=float)\n",
        "    parser.add_argument('--batch_size', default=2, type=int)\n",
        "    parser.add_argument('--weight_decay', default=1e-4, type=float)\n",
        "    parser.add_argument('--backbone', default='resnet50', type=str)\n",
        "    parser.add_argument('--dilation', action='store_true')\n",
        "    parser.add_argument('--position_embedding', default='sine', type=str)\n",
        "    parser.add_argument('--masks', action='store_true')\n",
        "    parser.add_argument('--device', default='cuda')\n",
        "    parser.add_argument('--dataset_file', default='coco', type=str)\n",
        "    parser.add_argument('--hidden_dim', default=256, type=int)\n",
        "    parser.add_argument('--dropout', default=0.1, type=float)\n",
        "    parser.add_argument('--nheads', default=8, type=int)\n",
        "    parser.add_argument('--dim_feedforward', default=2048, type=int)\n",
        "    parser.add_argument('--enc_layers', default=6, type=int)\n",
        "    parser.add_argument('--dec_layers', default=6, type=int)\n",
        "    parser.add_argument('--pre_norm', action='store_true')\n",
        "    parser.add_argument('--num_queries', default=100, type=int)\n",
        "    parser.add_argument('--aux_loss', action='store_true')\n",
        "    parser.add_argument('--set_cost_class', default=1, type=float)\n",
        "    parser.add_argument('--set_cost_bbox', default=5, type=float)\n",
        "    parser.add_argument('--set_cost_giou', default=2, type=float)\n",
        "    parser.add_argument('--bbox_loss_coef', default=5, type=float)\n",
        "    parser.add_argument('--giou_loss_coef', default=2, type=float)\n",
        "    parser.add_argument('--eos_coef', default=0.1, type=float)\n",
        "\n",
        "\n",
        "    return parser.parse_args([])\n",
        "\n",
        "def main():\n",
        "    args = get_args()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    dataset_train = coco.build('train', args)\n",
        "    dataset_val = coco.build('val', args)\n",
        "\n",
        "    sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
        "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
        "\n",
        "    batch_sampler_train = torch.utils.data.BatchSampler(sampler_train, args.batch_size, drop_last=True)\n",
        "\n",
        "    data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train, collate_fn=utils.collate_fn)\n",
        "    data_loader_val = DataLoader(dataset_val, batch_size=1, sampler=sampler_val, collate_fn=utils.collate_fn)\n",
        "\n",
        "    model, criterion, postprocessors = build_detr(args)\n",
        "    model.to(device)\n",
        "\n",
        "    param_dicts = [\n",
        "        {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
        "        {\"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad], \"lr\": args.lr * 0.1},\n",
        "    ]\n",
        "    optimizer = torch.optim.AdamW(param_dicts, lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "    for epoch in range(args.epochs):\n",
        "        train_stats = train_one_epoch(model, criterion, data_loader_train, optimizer, device, epoch)\n",
        "\n",
        "        base_ds = dataset_val.coco\n",
        "        _, coco_evaluator = evaluate(model, criterion, postprocessors, data_loader_val, dataset_val,device, args.output_dir)\n",
        "        if hasattr(coco_evaluator.coco_eval['bbox'], 'stats'):\n",
        "          map_score = coco_evaluator.coco_eval['bbox'].stats[0]\n",
        "          print(f\"Epoch {epoch+1} mAP: {map_score:.4f}\")\n",
        "        else:\n",
        "          print(f\"Epoch {epoch+1}: No valid mAP score found.\")\n",
        "        #print(f\"Epoch {epoch+1} mAP: {map_score:.4f}\")\n",
        "        #print(f\"Epoch {epoch+1} mAP: {map_score:.4f}\")\n",
        "\n",
        "        checkpoint_path = f\"{args.output_dir}/detr_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5N2yGcWop8u",
        "outputId": "432742c9-27c3-45a0-f869-432100132b2d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_detr_players.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/cvip/detr/models/detr_builder.py /content/cvip/detr/models/builder_detr.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btUGEfLLuE0t",
        "outputId": "eb557a3b-50e3-42d9-db5a-d6a6423c89ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/cvip/detr/models/detr_builder.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/cvip/detr/models/build.py /content/cvip/detr/models/builder_detr.py\n"
      ],
      "metadata": {
        "id": "6iwzS-p9von8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/cvip/detr/models/__init__.py"
      ],
      "metadata": {
        "id": "IVIq6MdIv20A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/np\\.float/float/g' /usr/local/lib/python3.11/dist-packages/pycocotools/cocoeval.py"
      ],
      "metadata": {
        "id": "Dj-q9fyiEeOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/cvip/detr\n",
        "!python train_detr_players.py --dataset_path \"/content/cvip/coco\" --output_dir \"./output\" --num_classes 2"
      ],
      "metadata": {
        "id": "WM20pkBDwcAx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bf_kywP2wcC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}